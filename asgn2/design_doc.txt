File: design_doc.txt
Author(s): Matt Ovenden, Ryan Blelloch

ASSIGNMENT 2 DESIGN DOCUMENT
--------------------------------------
Brief Description: We have modified kernel files to implement
a ticket lottery system for user timeshare processes. We have
created a benchmark program to test the result of our ticket
lottery system.  

------------------------------------
All files in REPO:
README                  - Directions for all compilation/running
design_doc.txt          - Full explanation of asgn2 implementation
benchmark.c             - Benchmark source code
kern/kern_switch.c      - Modified kern_switch.c kernel source file
kern/sched_ule.c        - Modified sched_ule.c kernel source file
sys/runq.h              - Modified runq.h kernel source file
Makefile                - Makefile with options to build and install 
                          kernel, and build benchmark

-----------------------------------
Source Files changed/explanation

kern/kern_switch.c
 - We implemented 3 new functions for mutating accessing the 
   queue.
   the lottery queue.
   - lottery_q_choose: chooses a process at random. A process with 
     a large number of tickets will be more likely be chosen than
     a process with few ticekts.
     - Process selection: If TAILQ is empty, return NULL. Otherwise,
       a random ticket number is generated by the following:
                    int r = random() % ticket_total;
       In this way it is possible to pick any process in the list.
       The list of processes is traversed, each time subtracting each
       process's ticket value from r until r < 0, at which point the
       thread whose ticket subtraction cause r < 0 is returned. 
     - In a more optimal version of our lottery sysem we would pass 
       an int * into lottery_q_choose that maintains the total number
       of lottery tickets. However, our implementation traveres the 
       process list to count the ticket total upon every call to 
       lottery_q_choose. It would be further optimal to compute and
       store a large list of random numbers at boot time to iterate
       around instead of wasting precious cycles generating a new
       random number on every call to lottery_q_choose.
       
   - lottery_q_add: adds thread *td into the 0th runq in the passed
     *runq struct. In this way all threads are added into the same 
     TAILQ, which eases thread selection later on. We insert a thread
     onto the head of the TAILQ. This design decision is orthogonal 
     to choosing a thread in lottery_q_choose.
     
   - lottery_q_remove closely mimicks the analogous freebsd function
     runq_remove. It takes a thread * and removes tht thread * from 
     the process list.

sys/runq.h
 - This file contains function declarations for the lottery_q 
   functions described above.
   
kern/sched_ule.c
 - This file contains 2 types of changes: 
   - 1 new structure and 1 new function.
     - runq structure in tdq class: tdq_lottery.
     - function isRoot(thread *) that checks the thread's
       user credentials.
       
   - calling lottery_q accessing and mutating functions.
     - each time runq_add(&tdq_timeshare, thread) or 
       runq_remove(&tdq_timeshare, thread) was called, we check if the
       thread is a root thread using isRoot(), and if it is not root
       we intercept that thread and call
       lottery_q_{add / remove}(&tdq_lottery, td) instead. 
     - When choosing a thread to run we had to decide which runq gets 
       priority over lottery_q. We recognized that lottery_q_choose
       had to be chosen immediately before or immediately after 
       runq_choose(&tdq_timeshare). Since tdq_timeshare now holds only
       root timeshare processes we elected to select a process from
       the lotter only if runq_choose(&tdq_timeshare) returned NULL.

-----------------------------------
Benchmark:

Build:
$ make benchmark
Run (as User):
$ ./benchmark <small positive integer (ex. 10)>

How it works:
The benchmark program runs five processes at roughly the same time,
forcing them to compete in the ticket lottery system queue.  

Results:

The Functionality Result proves the correct implementation of the 
ticket lottery system for User Timeshare processes.

The Time Result proves the trend of processes of higher ticket counts
being executed faster than processes of lower ticket counts.

Functionality Result: 
1. All User Timeshare processes print their process number, ticket 
number, and total number of tickets on the user timeshare queue 
when they are chosen from the queue. 
2. After the test, the system log is parsed using (dmesg) and (grep)
to find all of the user timeshare print statements. 
3. All system messages with total number of tickets equal to sum of
all test processes are considered. (This is done to avoid choices
made after one or more of the test processes have finished).
4. Each process gets the sum of the times it was chosen, and divides
it by the total number of choices, to give it a percentage.
5. This actual percentage is compared with the expected percentage 
of process priority / total priority.

Time Results:
1. At the end of every test process, it writes a time delta to a
file. 
2. All the time delta files are read and stored.
3. The results are printed sorted by the time taken. They are 
expected to be ordered by their priorities, giving a trend from
(large priority/small time delta) to (small priority/large time
delta)

-----------------------------------
Benchmark results:
    First we will display our benchmark results under root user 
    (no lottery scheduling), and then results under User (lottery 
    scheduling).
    Note: there are no statistics indicating how often a thread was 
    chosen from a queue outside of lottery scheduling.
    
 - Benchmark as Root (FreeBSD scheduling):
--------------------------------
   --pro----pri-----tim---
     756    20    10.181
     757    15     9.401
     758    10     8.591
     759     5     7.660
     760     0     5.876
--------------------------------

 - Benchmark as User (lottery scheduling):
 
0  tickets: Expected: 0.018182, Actual 0.020658
5  tickets: Expected: 0.109091, Actual 0.114002
10 tickets: Expected: 0.200000, Actual 0.208493
15 tickets: Expected: 0.290909, Actual 0.287299
20 tickets: Expected: 0.381818, Actual 0.369549
--------------------------------
  --pro---pri-----tim---
   776     0     6.397
   775     5     5.619
   774    10     4.957
   773    15     4.185
   772    20     3.731
--------------------------------

As we can see, processes with more tickets finish quicker. This is
because ther are more likely to be chosen to run on the CPU. The 
difference becomes more apparent as we increase the total loops 
from 2 to 10:

0  tickets: Expected: 0.018182, Actual 0.019797
5  tickets: Expected: 0.109091, Actual 0.099492
10 tickets: Expected: 0.200000, Actual 0.195431
15 tickets: Expected: 0.290909, Actual 0.313706
20 tickets: Expected: 0.381818, Actual 0.371574
--------------------------------
 --pro----pri-----tim---
   787     0    33.46
   786     5    28.123
   785    10    24.256
   784    15    20.973
   783    20    18.57
--------------------------------
